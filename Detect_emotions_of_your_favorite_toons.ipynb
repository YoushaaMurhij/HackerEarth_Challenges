{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detect emotions of your favorite toons.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNO22gSSbrxaWl7uuMPRno+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoushaaMurhij/HackerEarth_Challenges/blob/master/Detect_emotions_of_your_favorite_toons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip6v4lu8L2j-",
        "colab_type": "text"
      },
      "source": [
        "# HackerEarth Deep Learning challenge: Detect emotions of your favorite toons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CkQvDWZM8iG",
        "colab_type": "text"
      },
      "source": [
        "Downloading the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lgszxV_DYmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://he-s3.s3.amazonaws.com/media/hackathon/hackerearth-deep-learning-challenge-emotion-detection-tom-jerry-cartoon/detect-emotions-of-your-favorite-toons-7d2c0f23/96714c94-6-Dataset.zip testtt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0j_45-UEIDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q Dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtS_hfDpNB1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RawBzDxVNDgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1LA-n-cNLrK",
        "colab_type": "text"
      },
      "source": [
        "Generating Training dataset from video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3sZvXLRFvtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d163c87-b80e-4686-d1bb-3c934f552236"
      },
      "source": [
        "count = 0\n",
        "videoFile = \"Train Tom and jerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ShhXS_mNVmx",
        "colab_type": "text"
      },
      "source": [
        "Generating Testing dataset from video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn3N136AFyLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ad51b3b-fae4-46e7-fad6-09794b761cb6"
      },
      "source": [
        "count = 0\n",
        "videoFile = \"Test Tom and Jerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"test%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNdwWMpyYby2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d41690c-4a78-4945-ece8-3f4d4dc9ceb8"
      },
      "source": [
        "data.Emotion.unique()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy', 'surprised', 'angry', 'Unknown', 'sad'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R5Xr-pJYUf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tg_dict = {\"happy\":0, \"surprised\": 1, \"angry\": 2,\"Unknown\":3,\"sad\":4}\n",
        "def label_encode(x):\n",
        "    return tg_dict[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_P5k93YMVXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('Train.csv')\n",
        "test = pd.read_csv('Test.csv')\n",
        "X = []\n",
        "for img_name in data.Frame_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)\n",
        "X = np.array(X)\n",
        "\n",
        "X_test = []\n",
        "for img_name in test.Frame_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X_test.append(img)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "#train_y = np_utils.to_categorical(data.Emotion)\n",
        "#train_y = pd.Categorical(data.Emotion)\n",
        "train_yy = pd.Categorical(data.Emotion, categories=data.Emotion.unique()).codes\n",
        "train_y = np_utils.to_categorical(train_yy)\n",
        "\n",
        "#test_y = np_utils.to_categorical(test.Emotion)\n",
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
        "    image.append(a)\n",
        "X = np.array(image)\n",
        "\n",
        "iimage = []\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    a = resize(X_test[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
        "    iimage.append(a)\n",
        "X_test = np.array(iimage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH9u7YDSQ6wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a37835f0-a122-42a6-ca90-a2e3e9973dcc"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9rDXtJoMyJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob_5QZvTf_8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a912b7f6-8f7b-4d83-d483-0a25ca58d5ce"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYt4-T0kaeVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_test = X_test.reshape(186, 7*7*512)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db9JQ3UCap9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09776f93-5eb3-44d8-fe32-1069d18767e9"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYfftE1oawlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a28a2f2b-d972-4e2d-e3d7-10b102373a4e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(298, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHUhcqhZNp7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = preprocess_input(X, mode='tf')\n",
        "X_test = preprocess_input(X_test, mode='tf')\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, train_y, test_size=0.3, random_state=42)\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "X_test  = base_model.predict(X_test)\n",
        "\n",
        "X_train = X_train.reshape(208, 7*7*512)\n",
        "X_valid = X_valid.reshape(90, 7*7*512)\n",
        "X_test  = X_test.reshape(186, 7*7*512)\n",
        "\n",
        "train   = X_train/X_train.max()\n",
        "X_valid = X_valid/X_train.max()\n",
        "X_test  = X_test/X_test.max()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C5JKRd9NuaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid'))   # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=512, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=256, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(5, activation='softmax'))            # output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNV-MaLtFrH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "213268df-4233-42a5-914c-6e73dfa91712"
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "class_weights = compute_class_weight('balanced',np.unique(data.Emotion), data.Emotion)  # computing weights of different classes\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]      # model check pointing based on validation loss\n",
        "\n",
        "model.fit(train, y_train, epochs=500, validation_data=(X_valid, y_valid), class_weight=class_weights, callbacks=callbacks_list)\n",
        "\n",
        "model.load_weights(\"weights.best.hdf5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "scores = model.evaluate(X_valid, y_valid)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 208 samples, validate on 90 samples\n",
            "Epoch 1/500\n",
            "208/208 [==============================] - 1s 7ms/step - loss: 0.6341 - acc: 0.7933 - val_loss: 1.1373 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.13733, saving model to weights.best.hdf5\n",
            "Epoch 2/500\n",
            "208/208 [==============================] - 0s 919us/step - loss: 0.5433 - acc: 0.8269 - val_loss: 1.0657 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.13733 to 1.06573, saving model to weights.best.hdf5\n",
            "Epoch 3/500\n",
            "208/208 [==============================] - 0s 889us/step - loss: 0.5011 - acc: 0.8221 - val_loss: 1.1707 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.06573\n",
            "Epoch 4/500\n",
            "208/208 [==============================] - 0s 842us/step - loss: 0.4005 - acc: 0.8798 - val_loss: 1.1067 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.06573\n",
            "Epoch 5/500\n",
            "208/208 [==============================] - 0s 866us/step - loss: 0.3199 - acc: 0.9135 - val_loss: 1.1971 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.06573\n",
            "Epoch 6/500\n",
            "208/208 [==============================] - 0s 800us/step - loss: 0.2263 - acc: 0.9375 - val_loss: 1.1635 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.06573\n",
            "Epoch 7/500\n",
            "208/208 [==============================] - 0s 784us/step - loss: 0.2170 - acc: 0.9327 - val_loss: 1.2497 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.06573\n",
            "Epoch 8/500\n",
            "208/208 [==============================] - 0s 826us/step - loss: 0.1490 - acc: 0.9712 - val_loss: 1.2464 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.06573\n",
            "Epoch 9/500\n",
            "208/208 [==============================] - 0s 815us/step - loss: 0.1626 - acc: 0.9615 - val_loss: 1.2355 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.06573\n",
            "Epoch 10/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.1114 - acc: 0.9663 - val_loss: 1.2505 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.06573\n",
            "Epoch 11/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.1114 - acc: 0.9567 - val_loss: 1.3744 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.06573\n",
            "Epoch 12/500\n",
            "208/208 [==============================] - 0s 796us/step - loss: 0.0934 - acc: 0.9712 - val_loss: 1.3041 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.06573\n",
            "Epoch 13/500\n",
            "208/208 [==============================] - 0s 796us/step - loss: 0.0908 - acc: 0.9712 - val_loss: 1.4342 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.06573\n",
            "Epoch 14/500\n",
            "208/208 [==============================] - 0s 831us/step - loss: 0.0867 - acc: 0.9712 - val_loss: 1.3124 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.06573\n",
            "Epoch 15/500\n",
            "208/208 [==============================] - 0s 842us/step - loss: 0.0759 - acc: 0.9760 - val_loss: 1.2700 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.06573\n",
            "Epoch 16/500\n",
            "208/208 [==============================] - 0s 831us/step - loss: 0.0731 - acc: 0.9663 - val_loss: 1.3660 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.06573\n",
            "Epoch 17/500\n",
            "208/208 [==============================] - 0s 793us/step - loss: 0.0650 - acc: 0.9808 - val_loss: 1.3409 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.06573\n",
            "Epoch 18/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0736 - acc: 0.9904 - val_loss: 1.6354 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.06573\n",
            "Epoch 19/500\n",
            "208/208 [==============================] - 0s 804us/step - loss: 0.0603 - acc: 0.9808 - val_loss: 1.3870 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.06573\n",
            "Epoch 20/500\n",
            "208/208 [==============================] - 0s 834us/step - loss: 0.0756 - acc: 0.9663 - val_loss: 1.4113 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.06573\n",
            "Epoch 21/500\n",
            "208/208 [==============================] - 0s 820us/step - loss: 0.0512 - acc: 0.9808 - val_loss: 1.4672 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.06573\n",
            "Epoch 22/500\n",
            "208/208 [==============================] - 0s 816us/step - loss: 0.0672 - acc: 0.9808 - val_loss: 1.4224 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.06573\n",
            "Epoch 23/500\n",
            "208/208 [==============================] - 0s 808us/step - loss: 0.0351 - acc: 0.9904 - val_loss: 1.5925 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.06573\n",
            "Epoch 24/500\n",
            "208/208 [==============================] - 0s 825us/step - loss: 0.0499 - acc: 0.9808 - val_loss: 1.4761 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.06573\n",
            "Epoch 25/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0468 - acc: 0.9856 - val_loss: 1.5282 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.06573\n",
            "Epoch 26/500\n",
            "208/208 [==============================] - 0s 831us/step - loss: 0.0826 - acc: 0.9760 - val_loss: 1.5421 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.06573\n",
            "Epoch 27/500\n",
            "208/208 [==============================] - 0s 831us/step - loss: 0.0593 - acc: 0.9712 - val_loss: 1.4564 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.06573\n",
            "Epoch 28/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0382 - acc: 0.9856 - val_loss: 1.5314 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.06573\n",
            "Epoch 29/500\n",
            "208/208 [==============================] - 0s 813us/step - loss: 0.0373 - acc: 0.9856 - val_loss: 1.6543 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.06573\n",
            "Epoch 30/500\n",
            "208/208 [==============================] - 0s 797us/step - loss: 0.0442 - acc: 0.9808 - val_loss: 1.7556 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.06573\n",
            "Epoch 31/500\n",
            "208/208 [==============================] - 0s 792us/step - loss: 0.0424 - acc: 0.9856 - val_loss: 1.6597 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.06573\n",
            "Epoch 32/500\n",
            "208/208 [==============================] - 0s 807us/step - loss: 0.0443 - acc: 0.9856 - val_loss: 1.5548 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.06573\n",
            "Epoch 33/500\n",
            "208/208 [==============================] - 0s 811us/step - loss: 0.0413 - acc: 0.9904 - val_loss: 1.6304 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.06573\n",
            "Epoch 34/500\n",
            "208/208 [==============================] - 0s 824us/step - loss: 0.0326 - acc: 0.9904 - val_loss: 1.5972 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.06573\n",
            "Epoch 35/500\n",
            "208/208 [==============================] - 0s 793us/step - loss: 0.0412 - acc: 0.9904 - val_loss: 1.6205 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.06573\n",
            "Epoch 36/500\n",
            "208/208 [==============================] - 0s 789us/step - loss: 0.0359 - acc: 0.9904 - val_loss: 1.8677 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.06573\n",
            "Epoch 37/500\n",
            "208/208 [==============================] - 0s 792us/step - loss: 0.0539 - acc: 0.9808 - val_loss: 1.6470 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.06573\n",
            "Epoch 38/500\n",
            "208/208 [==============================] - 0s 806us/step - loss: 0.0427 - acc: 0.9856 - val_loss: 1.5494 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.06573\n",
            "Epoch 39/500\n",
            "208/208 [==============================] - 0s 824us/step - loss: 0.0276 - acc: 0.9952 - val_loss: 1.6376 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.06573\n",
            "Epoch 40/500\n",
            "208/208 [==============================] - 0s 818us/step - loss: 0.0394 - acc: 0.9904 - val_loss: 1.7118 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.06573\n",
            "Epoch 41/500\n",
            "208/208 [==============================] - 0s 812us/step - loss: 0.0420 - acc: 0.9808 - val_loss: 1.5357 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.06573\n",
            "Epoch 42/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.0710 - acc: 0.9856 - val_loss: 1.9383 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.06573\n",
            "Epoch 43/500\n",
            "208/208 [==============================] - 0s 823us/step - loss: 0.0473 - acc: 0.9904 - val_loss: 1.7021 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.06573\n",
            "Epoch 44/500\n",
            "208/208 [==============================] - 0s 864us/step - loss: 0.0326 - acc: 0.9904 - val_loss: 1.6255 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.06573\n",
            "Epoch 45/500\n",
            "208/208 [==============================] - 0s 831us/step - loss: 0.0280 - acc: 0.9856 - val_loss: 1.8290 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.06573\n",
            "Epoch 46/500\n",
            "208/208 [==============================] - 0s 805us/step - loss: 0.0498 - acc: 0.9760 - val_loss: 1.6775 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.06573\n",
            "Epoch 47/500\n",
            "208/208 [==============================] - 0s 798us/step - loss: 0.0469 - acc: 0.9904 - val_loss: 1.5837 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.06573\n",
            "Epoch 48/500\n",
            "208/208 [==============================] - 0s 809us/step - loss: 0.0260 - acc: 0.9952 - val_loss: 1.8307 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.06573\n",
            "Epoch 49/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.8147 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.06573\n",
            "Epoch 50/500\n",
            "208/208 [==============================] - 0s 829us/step - loss: 0.0414 - acc: 0.9904 - val_loss: 1.7472 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.06573\n",
            "Epoch 51/500\n",
            "208/208 [==============================] - 0s 823us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.6131 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.06573\n",
            "Epoch 52/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0227 - acc: 0.9952 - val_loss: 1.6637 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.06573\n",
            "Epoch 53/500\n",
            "208/208 [==============================] - 0s 828us/step - loss: 0.0229 - acc: 0.9904 - val_loss: 1.8665 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.06573\n",
            "Epoch 54/500\n",
            "208/208 [==============================] - 0s 830us/step - loss: 0.0342 - acc: 0.9856 - val_loss: 1.6435 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.06573\n",
            "Epoch 55/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.0430 - acc: 0.9808 - val_loss: 1.7022 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.06573\n",
            "Epoch 56/500\n",
            "208/208 [==============================] - 0s 829us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.8368 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.06573\n",
            "Epoch 57/500\n",
            "208/208 [==============================] - 0s 825us/step - loss: 0.0137 - acc: 0.9952 - val_loss: 1.7950 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.06573\n",
            "Epoch 58/500\n",
            "208/208 [==============================] - 0s 811us/step - loss: 0.0150 - acc: 0.9952 - val_loss: 1.7363 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.06573\n",
            "Epoch 59/500\n",
            "208/208 [==============================] - 0s 812us/step - loss: 0.0193 - acc: 0.9952 - val_loss: 1.6757 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.06573\n",
            "Epoch 60/500\n",
            "208/208 [==============================] - 0s 795us/step - loss: 0.0163 - acc: 0.9952 - val_loss: 1.7532 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.06573\n",
            "Epoch 61/500\n",
            "208/208 [==============================] - 0s 793us/step - loss: 0.0205 - acc: 0.9952 - val_loss: 1.9120 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.06573\n",
            "Epoch 62/500\n",
            "208/208 [==============================] - 0s 797us/step - loss: 0.0207 - acc: 0.9904 - val_loss: 1.8381 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.06573\n",
            "Epoch 63/500\n",
            "208/208 [==============================] - 0s 807us/step - loss: 0.0141 - acc: 0.9952 - val_loss: 1.7194 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.06573\n",
            "Epoch 64/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0237 - acc: 0.9856 - val_loss: 1.6679 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.06573\n",
            "Epoch 65/500\n",
            "208/208 [==============================] - 0s 816us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.0824 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.06573\n",
            "Epoch 66/500\n",
            "208/208 [==============================] - 0s 810us/step - loss: 0.0197 - acc: 0.9952 - val_loss: 2.0807 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.06573\n",
            "Epoch 67/500\n",
            "208/208 [==============================] - 0s 806us/step - loss: 0.0372 - acc: 0.9952 - val_loss: 1.9958 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.06573\n",
            "Epoch 68/500\n",
            "208/208 [==============================] - 0s 807us/step - loss: 0.0246 - acc: 0.9904 - val_loss: 1.9389 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.06573\n",
            "Epoch 69/500\n",
            "208/208 [==============================] - 0s 804us/step - loss: 0.0119 - acc: 0.9952 - val_loss: 2.0362 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.06573\n",
            "Epoch 70/500\n",
            "208/208 [==============================] - 0s 813us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 2.0737 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.06573\n",
            "Epoch 71/500\n",
            "208/208 [==============================] - 0s 791us/step - loss: 0.0091 - acc: 0.9952 - val_loss: 2.0971 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.06573\n",
            "Epoch 72/500\n",
            "208/208 [==============================] - 0s 816us/step - loss: 0.0117 - acc: 0.9952 - val_loss: 1.9578 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.06573\n",
            "Epoch 73/500\n",
            "208/208 [==============================] - 0s 816us/step - loss: 0.0107 - acc: 0.9952 - val_loss: 1.8334 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.06573\n",
            "Epoch 74/500\n",
            "208/208 [==============================] - 0s 838us/step - loss: 0.0305 - acc: 0.9904 - val_loss: 1.8294 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.06573\n",
            "Epoch 75/500\n",
            "208/208 [==============================] - 0s 815us/step - loss: 0.0181 - acc: 0.9904 - val_loss: 1.8673 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.06573\n",
            "Epoch 76/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0092 - acc: 0.9952 - val_loss: 1.8992 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.06573\n",
            "Epoch 77/500\n",
            "208/208 [==============================] - 0s 821us/step - loss: 0.0209 - acc: 0.9952 - val_loss: 1.9409 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.06573\n",
            "Epoch 78/500\n",
            "208/208 [==============================] - 0s 817us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.9318 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.06573\n",
            "Epoch 79/500\n",
            "208/208 [==============================] - 0s 807us/step - loss: 0.0119 - acc: 0.9952 - val_loss: 1.9585 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.06573\n",
            "Epoch 80/500\n",
            "208/208 [==============================] - 0s 817us/step - loss: 0.0078 - acc: 0.9952 - val_loss: 2.0002 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.06573\n",
            "Epoch 81/500\n",
            "208/208 [==============================] - 0s 820us/step - loss: 0.0158 - acc: 0.9952 - val_loss: 1.9553 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.06573\n",
            "Epoch 82/500\n",
            "208/208 [==============================] - 0s 812us/step - loss: 0.0138 - acc: 0.9952 - val_loss: 1.9390 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.06573\n",
            "Epoch 83/500\n",
            "208/208 [==============================] - 0s 791us/step - loss: 0.0123 - acc: 0.9952 - val_loss: 1.9469 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.06573\n",
            "Epoch 84/500\n",
            "208/208 [==============================] - 0s 800us/step - loss: 0.0110 - acc: 0.9952 - val_loss: 1.9418 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.06573\n",
            "Epoch 85/500\n",
            "208/208 [==============================] - 0s 823us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.9291 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.06573\n",
            "Epoch 86/500\n",
            "208/208 [==============================] - 0s 851us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.9458 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.06573\n",
            "Epoch 87/500\n",
            "208/208 [==============================] - 0s 816us/step - loss: 0.0120 - acc: 0.9952 - val_loss: 1.9828 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.06573\n",
            "Epoch 88/500\n",
            "208/208 [==============================] - 0s 832us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.9727 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.06573\n",
            "Epoch 89/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.9020 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.06573\n",
            "Epoch 90/500\n",
            "208/208 [==============================] - 0s 827us/step - loss: 0.0099 - acc: 0.9904 - val_loss: 1.8957 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.06573\n",
            "Epoch 91/500\n",
            "208/208 [==============================] - 0s 857us/step - loss: 0.0100 - acc: 0.9952 - val_loss: 1.9071 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.06573\n",
            "Epoch 92/500\n",
            "208/208 [==============================] - 0s 847us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.9266 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.06573\n",
            "Epoch 93/500\n",
            "208/208 [==============================] - 0s 848us/step - loss: 0.0200 - acc: 0.9904 - val_loss: 2.2977 - val_acc: 0.6111\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.06573\n",
            "Epoch 94/500\n",
            "208/208 [==============================] - 0s 830us/step - loss: 0.0395 - acc: 0.9904 - val_loss: 1.8242 - val_acc: 0.7000\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.06573\n",
            "Epoch 95/500\n",
            "208/208 [==============================] - 0s 821us/step - loss: 0.0500 - acc: 0.9808 - val_loss: 1.8482 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.06573\n",
            "Epoch 96/500\n",
            "208/208 [==============================] - 0s 821us/step - loss: 0.0148 - acc: 0.9904 - val_loss: 2.1129 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.06573\n",
            "Epoch 97/500\n",
            "208/208 [==============================] - 0s 827us/step - loss: 0.0227 - acc: 0.9904 - val_loss: 1.8503 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.06573\n",
            "Epoch 98/500\n",
            "208/208 [==============================] - 0s 862us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.7366 - val_acc: 0.7000\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.06573\n",
            "Epoch 99/500\n",
            "208/208 [==============================] - 0s 856us/step - loss: 0.0198 - acc: 0.9904 - val_loss: 1.8436 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.06573\n",
            "Epoch 100/500\n",
            "208/208 [==============================] - 0s 840us/step - loss: 0.0121 - acc: 0.9952 - val_loss: 1.9269 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.06573\n",
            "Epoch 101/500\n",
            "208/208 [==============================] - 0s 833us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.8166 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 1.06573\n",
            "Epoch 102/500\n",
            "208/208 [==============================] - 0s 847us/step - loss: 0.0303 - acc: 0.9904 - val_loss: 1.8207 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 1.06573\n",
            "Epoch 103/500\n",
            "208/208 [==============================] - 0s 983us/step - loss: 0.0230 - acc: 0.9856 - val_loss: 2.0331 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 1.06573\n",
            "Epoch 104/500\n",
            "208/208 [==============================] - 0s 914us/step - loss: 0.0239 - acc: 0.9856 - val_loss: 1.9675 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 1.06573\n",
            "Epoch 105/500\n",
            "208/208 [==============================] - 0s 814us/step - loss: 0.0127 - acc: 0.9904 - val_loss: 1.8402 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 1.06573\n",
            "Epoch 106/500\n",
            "208/208 [==============================] - 0s 835us/step - loss: 0.0137 - acc: 0.9952 - val_loss: 1.8344 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 1.06573\n",
            "Epoch 107/500\n",
            "208/208 [==============================] - 0s 802us/step - loss: 0.0142 - acc: 0.9952 - val_loss: 2.0091 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 1.06573\n",
            "Epoch 108/500\n",
            "208/208 [==============================] - 0s 790us/step - loss: 0.0106 - acc: 0.9952 - val_loss: 2.1200 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 1.06573\n",
            "Epoch 109/500\n",
            "208/208 [==============================] - 0s 845us/step - loss: 0.0257 - acc: 0.9904 - val_loss: 1.9134 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 1.06573\n",
            "Epoch 110/500\n",
            "208/208 [==============================] - 0s 810us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.8765 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 1.06573\n",
            "Epoch 111/500\n",
            "208/208 [==============================] - 0s 827us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.8869 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 1.06573\n",
            "Epoch 112/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0189 - acc: 0.9904 - val_loss: 1.9578 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 1.06573\n",
            "Epoch 113/500\n",
            "208/208 [==============================] - 0s 815us/step - loss: 0.0061 - acc: 0.9952 - val_loss: 1.9400 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 1.06573\n",
            "Epoch 114/500\n",
            "208/208 [==============================] - 0s 841us/step - loss: 0.0177 - acc: 0.9952 - val_loss: 1.8916 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 1.06573\n",
            "Epoch 115/500\n",
            "208/208 [==============================] - 0s 837us/step - loss: 0.0255 - acc: 0.9904 - val_loss: 1.9653 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 1.06573\n",
            "Epoch 116/500\n",
            "208/208 [==============================] - 0s 838us/step - loss: 0.0103 - acc: 0.9952 - val_loss: 2.0970 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 1.06573\n",
            "Epoch 117/500\n",
            "208/208 [==============================] - 0s 839us/step - loss: 0.0093 - acc: 0.9952 - val_loss: 2.0299 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 1.06573\n",
            "Epoch 118/500\n",
            "208/208 [==============================] - 0s 828us/step - loss: 0.0197 - acc: 0.9904 - val_loss: 1.9737 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 1.06573\n",
            "Epoch 119/500\n",
            "208/208 [==============================] - 0s 826us/step - loss: 0.0152 - acc: 0.9904 - val_loss: 1.9253 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 1.06573\n",
            "Epoch 120/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.9157 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 1.06573\n",
            "Epoch 121/500\n",
            "208/208 [==============================] - 0s 840us/step - loss: 0.0079 - acc: 0.9952 - val_loss: 1.9374 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 1.06573\n",
            "Epoch 122/500\n",
            "208/208 [==============================] - 0s 820us/step - loss: 0.0079 - acc: 0.9952 - val_loss: 1.9620 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 1.06573\n",
            "Epoch 123/500\n",
            "208/208 [==============================] - 0s 814us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.9794 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 1.06573\n",
            "Epoch 124/500\n",
            "208/208 [==============================] - 0s 819us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.0105 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 1.06573\n",
            "Epoch 125/500\n",
            "208/208 [==============================] - 0s 830us/step - loss: 0.0087 - acc: 0.9952 - val_loss: 2.0207 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 1.06573\n",
            "Epoch 126/500\n",
            "208/208 [==============================] - 0s 832us/step - loss: 0.0078 - acc: 0.9952 - val_loss: 2.0092 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 1.06573\n",
            "Epoch 127/500\n",
            "208/208 [==============================] - 0s 858us/step - loss: 0.0205 - acc: 0.9904 - val_loss: 1.9954 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 1.06573\n",
            "Epoch 128/500\n",
            "208/208 [==============================] - 0s 806us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.0030 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 1.06573\n",
            "Epoch 129/500\n",
            "208/208 [==============================] - 0s 815us/step - loss: 0.0125 - acc: 0.9904 - val_loss: 2.0160 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 1.06573\n",
            "Epoch 130/500\n",
            "208/208 [==============================] - 0s 809us/step - loss: 0.0084 - acc: 0.9904 - val_loss: 2.0049 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 1.06573\n",
            "Epoch 131/500\n",
            "208/208 [==============================] - 0s 809us/step - loss: 0.0077 - acc: 0.9952 - val_loss: 1.9936 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 1.06573\n",
            "Epoch 132/500\n",
            "208/208 [==============================] - 0s 845us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.0198 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 1.06573\n",
            "Epoch 133/500\n",
            "208/208 [==============================] - 0s 851us/step - loss: 0.0145 - acc: 0.9952 - val_loss: 2.0302 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 1.06573\n",
            "Epoch 134/500\n",
            "208/208 [==============================] - 0s 824us/step - loss: 0.0126 - acc: 0.9952 - val_loss: 2.0395 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 1.06573\n",
            "Epoch 135/500\n",
            "208/208 [==============================] - 0s 810us/step - loss: 0.0339 - acc: 0.9904 - val_loss: 2.0466 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 1.06573\n",
            "Epoch 136/500\n",
            "208/208 [==============================] - 0s 792us/step - loss: 0.0085 - acc: 0.9952 - val_loss: 2.0408 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 1.06573\n",
            "Epoch 137/500\n",
            "208/208 [==============================] - 0s 792us/step - loss: 0.0245 - acc: 0.9904 - val_loss: 1.9687 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 1.06573\n",
            "Epoch 138/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0111 - acc: 0.9952 - val_loss: 1.9785 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 1.06573\n",
            "Epoch 139/500\n",
            "208/208 [==============================] - 0s 817us/step - loss: 0.0156 - acc: 0.9904 - val_loss: 2.0172 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 1.06573\n",
            "Epoch 140/500\n",
            "208/208 [==============================] - 0s 806us/step - loss: 0.0160 - acc: 0.9904 - val_loss: 2.0566 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 1.06573\n",
            "Epoch 141/500\n",
            "208/208 [==============================] - 0s 814us/step - loss: 0.0079 - acc: 0.9952 - val_loss: 2.0354 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 1.06573\n",
            "Epoch 142/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.0190 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 1.06573\n",
            "Epoch 143/500\n",
            "208/208 [==============================] - 0s 817us/step - loss: 0.0082 - acc: 0.9952 - val_loss: 1.9999 - val_acc: 0.6556\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 1.06573\n",
            "Epoch 144/500\n",
            "208/208 [==============================] - 0s 807us/step - loss: 0.0099 - acc: 0.9952 - val_loss: 1.9951 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 1.06573\n",
            "Epoch 145/500\n",
            "208/208 [==============================] - 0s 835us/step - loss: 0.0055 - acc: 0.9952 - val_loss: 2.0002 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 1.06573\n",
            "Epoch 146/500\n",
            "208/208 [==============================] - 0s 815us/step - loss: 0.0223 - acc: 0.9904 - val_loss: 1.9915 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 1.06573\n",
            "Epoch 147/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0099 - acc: 0.9904 - val_loss: 1.9839 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 1.06573\n",
            "Epoch 148/500\n",
            "208/208 [==============================] - 0s 813us/step - loss: 0.0069 - acc: 0.9952 - val_loss: 1.9927 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 1.06573\n",
            "Epoch 149/500\n",
            "208/208 [==============================] - 0s 822us/step - loss: 0.0108 - acc: 0.9952 - val_loss: 2.0018 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 1.06573\n",
            "Epoch 150/500\n",
            "208/208 [==============================] - 0s 811us/step - loss: 0.0106 - acc: 0.9952 - val_loss: 2.0074 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 1.06573\n",
            "Epoch 151/500\n",
            "208/208 [==============================] - 0s 836us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.0100 - val_acc: 0.6778\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 1.06573\n",
            "Epoch 152/500\n",
            "208/208 [==============================] - 0s 825us/step - loss: 0.0111 - acc: 0.9904 - val_loss: 2.0051 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 1.06573\n",
            "Epoch 153/500\n",
            "208/208 [==============================] - 0s 803us/step - loss: 0.0096 - acc: 0.9952 - val_loss: 2.0286 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 1.06573\n",
            "Epoch 154/500\n",
            "208/208 [==============================] - 0s 802us/step - loss: 0.0257 - acc: 0.9904 - val_loss: 2.0744 - val_acc: 0.6889\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 1.06573\n",
            "Epoch 155/500\n",
            "128/208 [=================>............] - ETA: 0s - loss: 0.0116 - acc: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJHlke6OG1iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S3ItLMPYtUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=[]\n",
        "for i in preds:\n",
        "    predictions.append(np.argmax(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2A4oGVdYw0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['Emotion'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPNMqrFPYxfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gt_dict = dict((v,k) for k,v in tg_dict.items())\n",
        "\n",
        "def inverse_encode(x):\n",
        "    return gt_dict[x]\n",
        "\n",
        "test['Emotion'] = test['Emotion'].apply(inverse_encode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Ab70E6Y1GH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f92dcc74-6df2-4dd0-ccaa-199c0791b765"
      },
      "source": [
        "test.head(4)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frame_ID</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test0.jpg</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test1.jpg</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test2.jpg</td>\n",
              "      <td>Unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test3.jpg</td>\n",
              "      <td>Unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Frame_ID  Emotion\n",
              "0  test0.jpg    happy\n",
              "1  test1.jpg    happy\n",
              "2  test2.jpg  Unknown\n",
              "3  test3.jpg  Unknown"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNvlKipXY2rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('Submission.csv',header=True,index = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSpOCJ7OiwLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}